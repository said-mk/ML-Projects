{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOLIOZNZzDhzo3HFrb/cFNE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/said-mk/ML-Projects/blob/main/MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST Handwritten Digit Recognition in PyTorch"
      ],
      "metadata": {
        "id": "yOrXKMw865kT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modules used\n"
      ],
      "metadata": {
        "id": "T_S6S2vG7c3-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "84_NRyM-ZU7k"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data.dataloader import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Device Configuration"
      ],
      "metadata": {
        "id": "-L2ICGLZ7ppw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "id": "WjjinXYz7izw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset and Dataloader\n",
        "\n",
        "used MNIST Handwritten Digit from\n",
        "\n",
        "```\n",
        "torchvision.datasets\n",
        "```\n",
        "and used Dataloder to load it in batches of 64\n",
        "\n"
      ],
      "metadata": {
        "id": "KHRWAOh673Fq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform = transforms.ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    transform=transforms.ToTensor(),\n",
        "    download=True,\n",
        "    train=False\n",
        ")"
      ],
      "metadata": {
        "id": "eFhQ1DuGaEMh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dcf607b-c74c-48ac-d61b-b56ab6977805"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 20.0MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 484kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.50MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 7.17MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    dataset=train_data,\n",
        "    shuffle=True,\n",
        "    batch_size=64,\n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset= test_data,\n",
        "    pin_memory=True,\n",
        "    num_workers=4,\n",
        "    batch_size=64,\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7aR-MTRALwM",
        "outputId": "ac388659-b7c8-4d41-bb9a-2101935d8f08"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Architecture"
      ],
      "metadata": {
        "id": "OWBGzjkr9g05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1,32,3,1)\n",
        "    self.conv2 = nn.Conv2d(32,64,3,1)\n",
        "    self.conv3 = nn.Conv2d(64,128,3,1)\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.dropout1= nn.Dropout(0.25)\n",
        "    self.dropout2 = nn.Dropout(0.5)\n",
        "    self.fc1 = nn.Linear(1152,128)\n",
        "    self.fc2 = nn.Linear(128,10)\n",
        "\n",
        "  def forward(self,x):\n",
        "    # First Conv layer\n",
        "    x  = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x,2)\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    # Second Conv Layer\n",
        "    x = self.conv2(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x,2)\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    # Third Conv Layer\n",
        "    x = self.conv3(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    # Dense Layer\n",
        "    x = self.flatten(x)\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.dropout2(x)\n",
        "\n",
        "    # classifaction logits\n",
        "    logits = self.fc2(x)\n",
        "\n",
        "    return logits\n",
        "\n",
        "model = MNISTNet().to(device)"
      ],
      "metadata": {
        "id": "OAQDD_JRaNCJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Loop\n",
        "\n",
        "will be used to train the model"
      ],
      "metadata": {
        "id": "hpp-xSC292Zf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(model,loader,device,criterion,optimizer):\n",
        "  model.train()\n",
        "  size = len(loader.dataset)\n",
        "\n",
        "  for batch_idx, (data,target) in enumerate(loader):\n",
        "    data = data.to(device)\n",
        "    target = target.to(device)\n",
        "\n",
        "    # prediction and loss\n",
        "    predictions = model(data)\n",
        "    loss = criterion(predictions, target)\n",
        "\n",
        "    # Backpropaagtion\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if batch_idx % 100 == 0:\n",
        "      loss = loss.item()\n",
        "      current = batch_idx * batch_size + len(data)\n",
        "      print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "Zu2S8Oy71OdL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing Loop\n",
        "\n",
        "will be use to evaluate the model (accurracy on unseen sample)"
      ],
      "metadata": {
        "id": "pdZxwnXX-Hsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_loop(model,loader,criterion,device):\n",
        "  model.eval()\n",
        "  total_sample = len(loader.dataset)\n",
        "  num_batches = len(loader)\n",
        "  test_loss = 0\n",
        "  correct_pred = 0\n",
        "\n",
        "\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for data, target in loader:\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      predictions = model(data)\n",
        "      loss = criterion(predictions,target)\n",
        "\n",
        "      test_loss += loss.item()\n",
        "      # Accumulate loss (weighted by batch size for accurate average)\n",
        "      # test_loss += loss.item() * data.size(0)\n",
        "      correct_pred += (predictions.argmax(1) == target).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss = test_loss/num_batches\n",
        "    correct_pred = correct_pred/total_sample\n",
        "\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct_pred):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "z6xNVTDYfN06"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameters\n",
        "\n",
        "adjustable parameters that let you control the model optimization process. Different hyperparameter values can impact model training and convergence rates"
      ],
      "metadata": {
        "id": "6qAsNrIT-pY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-3\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "# Initialize the loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "jsTVBagGg2Y4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training and evaluating model"
      ],
      "metadata": {
        "id": "2cnDo_PV_Ekd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "  train_loop(model,train_loader,device,loss_fn,optimizer)\n",
        "  test_loop(model,test_loader,loss_fn,device)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_gKhqpGzO6E",
        "outputId": "c03433df-0bcb-4a68-df84-2441ffe94ffd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.315014  [   64/60000]\n",
            "loss: 2.285228  [ 6464/60000]\n",
            "loss: 2.315535  [12864/60000]\n",
            "loss: 2.311386  [19264/60000]\n",
            "loss: 2.300491  [25664/60000]\n",
            "loss: 2.292942  [32064/60000]\n",
            "loss: 2.292917  [38464/60000]\n",
            "loss: 2.303175  [44864/60000]\n",
            "loss: 2.303821  [51264/60000]\n",
            "loss: 2.310831  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 16.9%, Avg loss: 2.298594 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.297364  [   64/60000]\n",
            "loss: 2.292327  [ 6464/60000]\n",
            "loss: 2.298768  [12864/60000]\n",
            "loss: 2.291347  [19264/60000]\n",
            "loss: 2.287547  [25664/60000]\n",
            "loss: 2.308015  [32064/60000]\n",
            "loss: 2.291116  [38464/60000]\n",
            "loss: 2.311653  [44864/60000]\n",
            "loss: 2.301008  [51264/60000]\n",
            "loss: 2.293400  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 24.3%, Avg loss: 2.292574 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 2.289963  [   64/60000]\n",
            "loss: 2.306777  [ 6464/60000]\n",
            "loss: 2.280674  [12864/60000]\n",
            "loss: 2.292750  [19264/60000]\n",
            "loss: 2.295671  [25664/60000]\n",
            "loss: 2.297112  [32064/60000]\n",
            "loss: 2.293273  [38464/60000]\n",
            "loss: 2.280099  [44864/60000]\n",
            "loss: 2.287560  [51264/60000]\n",
            "loss: 2.282567  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 38.5%, Avg loss: 2.283988 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 2.300036  [   64/60000]\n",
            "loss: 2.291008  [ 6464/60000]\n",
            "loss: 2.295561  [12864/60000]\n",
            "loss: 2.263701  [19264/60000]\n",
            "loss: 2.272743  [25664/60000]\n",
            "loss: 2.266742  [32064/60000]\n",
            "loss: 2.284006  [38464/60000]\n",
            "loss: 2.276453  [44864/60000]\n",
            "loss: 2.269692  [51264/60000]\n",
            "loss: 2.285941  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 40.5%, Avg loss: 2.268723 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 2.280668  [   64/60000]\n",
            "loss: 2.268815  [ 6464/60000]\n",
            "loss: 2.271651  [12864/60000]\n",
            "loss: 2.277574  [19264/60000]\n",
            "loss: 2.277987  [25664/60000]\n",
            "loss: 2.265977  [32064/60000]\n",
            "loss: 2.274753  [38464/60000]\n",
            "loss: 2.245352  [44864/60000]\n",
            "loss: 2.262046  [51264/60000]\n",
            "loss: 2.223849  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 43.3%, Avg loss: 2.236432 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 2.261911  [   64/60000]\n",
            "loss: 2.233198  [ 6464/60000]\n",
            "loss: 2.238688  [12864/60000]\n",
            "loss: 2.221391  [19264/60000]\n",
            "loss: 2.208236  [25664/60000]\n",
            "loss: 2.209709  [32064/60000]\n",
            "loss: 2.205345  [38464/60000]\n",
            "loss: 2.189538  [44864/60000]\n",
            "loss: 2.181544  [51264/60000]\n",
            "loss: 2.163188  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 60.2%, Avg loss: 2.151272 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 2.153728  [   64/60000]\n",
            "loss: 2.125072  [ 6464/60000]\n",
            "loss: 2.121121  [12864/60000]\n",
            "loss: 2.167695  [19264/60000]\n",
            "loss: 2.089808  [25664/60000]\n",
            "loss: 2.049004  [32064/60000]\n",
            "loss: 1.988933  [38464/60000]\n",
            "loss: 1.962462  [44864/60000]\n",
            "loss: 1.982638  [51264/60000]\n",
            "loss: 1.920261  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 67.3%, Avg loss: 1.838982 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 1.973918  [   64/60000]\n",
            "loss: 1.927914  [ 6464/60000]\n",
            "loss: 1.738198  [12864/60000]\n",
            "loss: 1.717939  [19264/60000]\n",
            "loss: 1.730404  [25664/60000]\n",
            "loss: 1.648653  [32064/60000]\n",
            "loss: 1.588513  [38464/60000]\n",
            "loss: 1.623211  [44864/60000]\n",
            "loss: 1.561790  [51264/60000]\n",
            "loss: 1.398283  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 74.4%, Avg loss: 1.195067 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 1.312952  [   64/60000]\n",
            "loss: 1.508908  [ 6464/60000]\n",
            "loss: 1.191021  [12864/60000]\n",
            "loss: 1.413410  [19264/60000]\n",
            "loss: 1.190537  [25664/60000]\n",
            "loss: 1.192760  [32064/60000]\n",
            "loss: 1.031785  [38464/60000]\n",
            "loss: 1.114790  [44864/60000]\n",
            "loss: 1.341321  [51264/60000]\n",
            "loss: 1.153088  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 79.7%, Avg loss: 0.820646 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.880953  [   64/60000]\n",
            "loss: 1.087325  [ 6464/60000]\n",
            "loss: 1.136802  [12864/60000]\n",
            "loss: 1.053566  [19264/60000]\n",
            "loss: 1.080422  [25664/60000]\n",
            "loss: 1.031504  [32064/60000]\n",
            "loss: 1.447075  [38464/60000]\n",
            "loss: 1.062341  [44864/60000]\n",
            "loss: 1.094569  [51264/60000]\n",
            "loss: 0.776910  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.2%, Avg loss: 0.671470 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving the Model\n",
        "save the trained model. saving model saves re-**training** it every time you want to use it for predictions."
      ],
      "metadata": {
        "id": "WZiioLyo_QDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"mnist_cnn.pth\")\n"
      ],
      "metadata": {
        "id": "ifjxhUOwXnWR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the model and visualizaing test sample"
      ],
      "metadata": {
        "id": "3Dz5wYQiArvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_test_samples(model, loader, device, num_images=5):\n",
        "    model.eval()\n",
        "\n",
        "    try:\n",
        "        data_iter = iter(loader)\n",
        "        images, targets = next(data_iter)\n",
        "    except StopIteration:\n",
        "        print(\"Error: DataLoader is empty or finished.\")\n",
        "        return\n",
        "\n",
        "    if num_images > 12:\n",
        "      print(\"Max number of image = 12\")\n",
        "      print(\"Maximun number images exceed!\")\n",
        "      print(\"Images reduced to 12.\")\n",
        "      num_images = 12\n",
        "\n",
        "    images = images.to(device)\n",
        "\n",
        "    # Predictions\n",
        "    with torch.no_grad():\n",
        "        logits = model(images)\n",
        "        # Get the predicted class index\n",
        "        predictions = logits.argmax(1).cpu().numpy()\n",
        "\n",
        "    # Move original data to CPU for plotting\n",
        "    images_cpu = images.cpu().numpy()\n",
        "    targets_cpu = targets.cpu().numpy()\n",
        "\n",
        "\n",
        "    plot_count = num_images\n",
        "    fig, axes = plt.subplots(1, plot_count, figsize=(15, 3.5))\n",
        "\n",
        "    print(f\"\\nDisplaying {plot_count} predictions:\")\n",
        "\n",
        "    if num_images == 1: # Error Handling:\n",
        "      axes = [axes]     # TypeError: 'Axes' object is not subscriptable\n",
        "    for i in range(plot_count):\n",
        "        image = images_cpu[i].squeeze()\n",
        "\n",
        "        true_label = targets_cpu[i]\n",
        "        predicted_label = predictions[i]\n",
        "\n",
        "        # Set color and text for visualization\n",
        "        color = 'green' if true_label == predicted_label else 'red'\n",
        "\n",
        "        # Plot the image\n",
        "        axes[i].imshow(image, cmap='gray')\n",
        "\n",
        "        # Predicted Label\n",
        "        axes[i].set_title(f\"Predicted: {predicted_label}\", color=color, fontsize=10)\n",
        "\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "XrAF01PatEyH"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_images = torch.randint(1,10,[1]).item()\n",
        "\n",
        "visualize_test_samples(model, test_loader, device, num_images=num_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "2RTSIBN5tKIr",
        "outputId": "eec83634-894b-43ae-8be0-e41585eb6643"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Displaying 3 predictions:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x350 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}